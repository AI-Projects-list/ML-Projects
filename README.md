# ML Project Flow - Complete Documentation

## Project Overview
This is an end-to-end Machine Learning project built with **Clean + Hexagonal Architecture**, supporting multiple data formats and ML models with a complete pipeline from data ingestion to prediction.

---

## ğŸ—ï¸ Architecture Layers

### 1. **Domain Layer** (Business Logic Core)
- **Entities**: Core business objects (DataSource, ProcessedData, TrainedModel, etc.)
- **Value Objects**: Immutable objects (FileMetadata, DataQuality, etc.)
- **Repository Interfaces**: Contracts for data access
- **No Dependencies**: Pure business logic

### 2. **Application Layer** (Use Cases)
- **Use Cases**: Orchestrate business workflows
  - `DataIngestionUseCase`: Data loading and preprocessing
  - `EDAUseCase`: Exploratory data analysis
  - `ModelTrainingUseCase`: Model training workflow
  - `PredictionUseCase`: Prediction workflow
  - `MLPipelineUseCase`: Complete end-to-end pipeline

### 3. **Infrastructure Layer** (Technical Implementation)
- **Data Readers**: CSV, TXT, PDF, Scanned PDF (OCR)
- **Data Processors**: Cleaning, transformation, validation
- **EDA Analyzer**: Statistical analysis and visualizations
- **ML Components**: Model trainers, predictors, repository
- **Configuration**: Settings, logging, dependency injection

### 4. **Presentation Layer** (User Interface)
- **CLI**: Typer-based command-line interface
- **Commands**: run-pipeline, ingest, eda, train, predict

---

## ğŸ“Š Complete System Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INPUT                               â”‚
â”‚  (CLI Command / Python Script / Direct API Call)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PRESENTATION LAYER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CLI Application (src/presentation/cli.py)                â”‚  â”‚
â”‚  â”‚  - Parse arguments                                        â”‚  â”‚
â”‚  â”‚  - Validate inputs                                        â”‚  â”‚
â”‚  â”‚  - Initialize container                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APPLICATION LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Use Case Selection:                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚
â”‚  â”‚  â”‚ ML Pipeline UC â”‚  â”‚ Data Ingest UC â”‚                  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚
â”‚  â”‚  â”‚   EDA UC       â”‚  â”‚  Training UC   â”‚                  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚  â”‚
â”‚  â”‚  â”‚ Prediction UC  â”‚                                       â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INFRASTRUCTURE LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Data Processing Pipeline:                                â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  [Reader] â†’ [Processor] â†’ [Analyzer] â†’ [Trainer/Predictor]â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  Components:                                              â”‚  â”‚
â”‚  â”‚  â€¢ Data Readers (CSV, TXT, PDF, PDF+OCR)                 â”‚  â”‚
â”‚  â”‚  â€¢ Data Processor (Clean, Transform, Validate)           â”‚  â”‚
â”‚  â”‚  â€¢ EDA Analyzer (Statistics, Visualizations)             â”‚  â”‚
â”‚  â”‚  â€¢ Model Trainer (5 ML Models)                           â”‚  â”‚
â”‚  â”‚  â€¢ Predictor (Inference Engine)                          â”‚  â”‚
â”‚  â”‚  â€¢ Repositories (Data, Model Persistence)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DOMAIN LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Business Entities & Rules:                               â”‚  â”‚
â”‚  â”‚  â€¢ DataSource      â€¢ ProcessedData                        â”‚  â”‚
â”‚  â”‚  â€¢ EDAReport       â€¢ ModelConfig                          â”‚  â”‚
â”‚  â”‚  â€¢ TrainedModel    â€¢ Prediction                           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  Repository Interfaces (Contracts)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ End-to-End Pipeline Flow (Detailed)

```
START
  â”‚
  â”œâ”€â–º [1] DATA PREPARATION
  â”‚    â”‚
  â”‚    â”œâ”€ Identify data source (CSV/TXT/PDF/Scanned PDF)
  â”‚    â”œâ”€ Create DataSource entity
  â”‚    â””â”€ Configure model settings (ModelConfig)
  â”‚
  â”œâ”€â–º [2] DATA INGESTION
  â”‚    â”‚
  â”‚    â”œâ”€ Select appropriate reader
  â”‚    â”‚   â”œâ”€ CSVDataReader
  â”‚    â”‚   â”œâ”€ TextDataReader
  â”‚    â”‚   â”œâ”€ PDFDataReader
  â”‚    â”‚   â””â”€ ScannedPDFDataReader (with OCR)
  â”‚    â”‚
  â”‚    â”œâ”€ Read data into DataFrame
  â”‚    â”‚
  â”‚    â”œâ”€ DATA CLEANING
  â”‚    â”‚   â”œâ”€ Handle missing values
  â”‚    â”‚   â”‚   â”œâ”€ Numeric: Fill with median
  â”‚    â”‚   â”‚   â””â”€ Categorical: Fill with mode
  â”‚    â”‚   â”œâ”€ Remove duplicates
  â”‚    â”‚   â””â”€ Handle outliers (optional)
  â”‚    â”‚
  â”‚    â”œâ”€ DATA TRANSFORMATION
  â”‚    â”‚   â”œâ”€ Identify column types
  â”‚    â”‚   â”‚   â”œâ”€ Numeric columns
  â”‚    â”‚   â”‚   â”œâ”€ Categorical columns
  â”‚    â”‚   â”‚   â””â”€ Datetime columns
  â”‚    â”‚   â”‚
  â”‚    â”‚   â”œâ”€ Encode categorical variables
  â”‚    â”‚   â”‚   â””â”€ Label Encoding (Aâ†’0, Bâ†’1, Câ†’2)
  â”‚    â”‚   â”‚
  â”‚    â”‚   â”œâ”€ Scale numeric features (optional)
  â”‚    â”‚   â””â”€ Parse datetime columns
  â”‚    â”‚
  â”‚    â”œâ”€ DATA VALIDATION
  â”‚    â”‚   â”œâ”€ Completeness check (missing values %)
  â”‚    â”‚   â”œâ”€ Consistency check (data types)
  â”‚    â”‚   â”œâ”€ Validity check (value ranges)
  â”‚    â”‚   â””â”€ Generate quality score
  â”‚    â”‚
  â”‚    â””â”€ Create ProcessedData entity
  â”‚
  â”œâ”€â–º [3] EXPLORATORY DATA ANALYSIS (EDA)
  â”‚    â”‚
  â”‚    â”œâ”€ Statistical Analysis
  â”‚    â”‚   â”œâ”€ Descriptive statistics
  â”‚    â”‚   â”‚   â”œâ”€ Mean, median, std dev
  â”‚    â”‚   â”‚   â”œâ”€ Min, max, quartiles
  â”‚    â”‚   â”‚   â””â”€ Count, unique values
  â”‚    â”‚   â”‚
  â”‚    â”‚   â”œâ”€ Correlation analysis
  â”‚    â”‚   â”‚   â””â”€ Feature correlations
  â”‚    â”‚   â”‚
  â”‚    â”‚   â”œâ”€ Outlier detection
  â”‚    â”‚   â”‚   â””â”€ IQR method
  â”‚    â”‚   â”‚
  â”‚    â”‚   â””â”€ Distribution analysis
  â”‚    â”‚
  â”‚    â”œâ”€ Visualizations
  â”‚    â”‚   â”œâ”€ Distribution plots
  â”‚    â”‚   â”‚   â””â”€ Histograms for all numeric features
  â”‚    â”‚   â”‚
  â”‚    â”‚   â”œâ”€ Correlation heatmap
  â”‚    â”‚   â”‚   â””â”€ Feature correlation matrix
  â”‚    â”‚   â”‚
  â”‚    â”‚   â””â”€ Outlier boxplots
  â”‚    â”‚       â””â”€ Boxplots for numeric features
  â”‚    â”‚
  â”‚    â”œâ”€ Generate insights
  â”‚    â”‚   â”œâ”€ Dataset size and shape
  â”‚    â”‚   â”œâ”€ Outlier counts per feature
  â”‚    â”‚   â””â”€ Key patterns detected
  â”‚    â”‚
  â”‚    â””â”€ Create EDAReport entity
  â”‚
  â”œâ”€â–º [4] MODEL TRAINING
  â”‚    â”‚
  â”‚    â”œâ”€ Prepare training data
  â”‚    â”‚   â”œâ”€ Select features (X)
  â”‚    â”‚   â”œâ”€ Extract target (y)
  â”‚    â”‚   â””â”€ Train/test split (80/20)
  â”‚    â”‚
  â”‚    â”œâ”€ Select ML model
  â”‚    â”‚   â”œâ”€ Linear Regression (regression)
  â”‚    â”‚   â”œâ”€ Logistic Regression (classification)
  â”‚    â”‚   â”œâ”€ Decision Tree (classification/regression)
  â”‚    â”‚   â”œâ”€ Random Forest (classification/regression)
  â”‚    â”‚   â””â”€ Gradient Boosting (classification/regression)
  â”‚    â”‚
  â”‚    â”œâ”€ Train model
  â”‚    â”‚   â”œâ”€ Fit model on training data
  â”‚    â”‚   â””â”€ Apply hyperparameters
  â”‚    â”‚
  â”‚    â”œâ”€ Evaluate model
  â”‚    â”‚   â”œâ”€ Make predictions on test set
  â”‚    â”‚   â”œâ”€ Calculate metrics
  â”‚    â”‚   â”‚   â”œâ”€ Classification: accuracy, precision, recall, F1
  â”‚    â”‚   â”‚   â””â”€ Regression: MSE, RMSE, MAE, RÂ²
  â”‚    â”‚   â”‚
  â”‚    â”‚   â””â”€ Extract feature importance (if available)
  â”‚    â”‚
  â”‚    â”œâ”€ Save model
  â”‚    â”‚   â””â”€ Pickle to .pkl file
  â”‚    â”‚
  â”‚    â””â”€ Create TrainedModel entity
  â”‚
  â”œâ”€â–º [5] PREDICTION
  â”‚    â”‚
  â”‚    â”œâ”€ Load trained model from disk
  â”‚    â”‚
  â”‚    â”œâ”€ Prepare input data
  â”‚    â”‚   â”œâ”€ Select same features as training
  â”‚    â”‚   â”œâ”€ Handle missing values (fill with 0)
  â”‚    â”‚   â””â”€ Encode categorical variables
  â”‚    â”‚
  â”‚    â”œâ”€ Make predictions
  â”‚    â”‚   â”œâ”€ Model.predict(X)
  â”‚    â”‚   â””â”€ Get confidence scores (if classifier)
  â”‚    â”‚       â””â”€ Model.predict_proba(X)
  â”‚    â”‚
  â”‚    â”œâ”€ Post-process results
  â”‚    â”‚   â”œâ”€ Attach predictions to original data
  â”‚    â”‚   â”œâ”€ Add confidence scores
  â”‚    â”‚   â””â”€ Calculate accuracy (if labels available)
  â”‚    â”‚
  â”‚    â”œâ”€ Save predictions
  â”‚    â”‚   â””â”€ Export to CSV
  â”‚    â”‚
  â”‚    â””â”€ Create Prediction entity
  â”‚
  â””â”€â–º END
       â”‚
       â””â”€ Return results to user
```

---

## ğŸ“ Data Flow Through System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data      â”‚
â”‚  (CSV/TXT/PDF)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Reader    â”‚ â”€â”€â–º Factory Pattern
â”‚   (Interface)   â”‚     Selects appropriate reader
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DataFrame     â”‚
â”‚  (Raw Data)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Processor  â”‚
â”‚   - Clean       â”‚ â”€â”€â–º Handle missing, duplicates
â”‚   - Transform   â”‚ â”€â”€â–º Encode, scale, parse
â”‚   - Validate    â”‚ â”€â”€â–º Quality checks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ProcessedData   â”‚ â”€â”€â–º Entity with metadata
â”‚   DataFrame +   â”‚     Processing steps
â”‚   Metadata      â”‚     Quality metrics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EDA Analyzer   â”‚  â”‚ Model Trainer   â”‚  â”‚   Repository    â”‚
â”‚  - Statistics   â”‚  â”‚  - Split data   â”‚  â”‚   - Save data   â”‚
â”‚  - Visuals      â”‚  â”‚  - Train model  â”‚  â”‚   - Load data   â”‚
â”‚  - Insights     â”‚  â”‚  - Evaluate     â”‚  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EDAReport     â”‚  â”‚  TrainedModel   â”‚
â”‚  - Insights     â”‚  â”‚   - Model obj   â”‚
â”‚  - Statistics   â”‚  â”‚   - Metrics     â”‚
â”‚  - Visuals path â”‚  â”‚   - Features    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚    Predictor    â”‚
                     â”‚  - Load model   â”‚
                     â”‚  - Predict      â”‚
                     â”‚  - Confidence   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Prediction    â”‚
                     â”‚  - Predictions  â”‚
                     â”‚  - Confidence   â”‚
                     â”‚  - Metadata     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Use Case Execution Flow

### 1. **Data Ingestion Use Case**
```
execute(source, clean=True, transform=True)
  â”‚
  â”œâ”€â–º Get reader from factory
  â”‚    â””â”€â–º reader = factory.get_reader(source.source_type)
  â”‚
  â”œâ”€â–º Read data
  â”‚    â””â”€â–º raw_data = reader.read(source)
  â”‚
  â”œâ”€â–º Clean data (if clean=True)
  â”‚    â”œâ”€â–º Handle missing values
  â”‚    â”œâ”€â–º Remove duplicates
  â”‚    â””â”€â–º Log cleaning stats
  â”‚
  â”œâ”€â–º Transform data (if transform=True)
  â”‚    â”œâ”€â–º Encode categoricals
  â”‚    â”œâ”€â–º Scale numerics
  â”‚    â””â”€â–º Parse datetimes
  â”‚
  â”œâ”€â–º Validate data
  â”‚    â”œâ”€â–º Check completeness
  â”‚    â”œâ”€â–º Check consistency
  â”‚    â””â”€â–º Calculate quality score
  â”‚
  â””â”€â–º Return ProcessedData entity
```

### 2. **EDA Use Case**
```
execute(data, generate_plots=True, output_dir=None)
  â”‚
  â”œâ”€â–º Analyze data
  â”‚    â”œâ”€â–º Calculate statistics
  â”‚    â”œâ”€â–º Find correlations
  â”‚    â”œâ”€â–º Detect outliers
  â”‚    â””â”€â–º Generate insights
  â”‚
  â”œâ”€â–º Generate visualizations (if generate_plots=True)
  â”‚    â”œâ”€â–º Distribution plots
  â”‚    â”œâ”€â–º Correlation heatmap
  â”‚    â”œâ”€â–º Outlier boxplots
  â”‚    â””â”€â–º Save to output_dir
  â”‚
  â””â”€â–º Return EDAReport entity
```

### 3. **Model Training Use Case**
```
execute(data, config, save_model=True, model_path=None)
  â”‚
  â”œâ”€â–º Train model
  â”‚    â”œâ”€â–º Prepare data (X, y split)
  â”‚    â”œâ”€â–º Train/test split
  â”‚    â”œâ”€â–º Fit model
  â”‚    â””â”€â–º Evaluate on test set
  â”‚
  â”œâ”€â–º Calculate metrics
  â”‚    â”œâ”€â–º Accuracy, precision, recall (classification)
  â”‚    â””â”€â–º MSE, RMSE, RÂ² (regression)
  â”‚
  â”œâ”€â–º Extract feature importance
  â”‚
  â”œâ”€â–º Save model (if save_model=True)
  â”‚    â””â”€â–º repository.save(model, model_path)
  â”‚
  â””â”€â–º Return TrainedModel entity
```

### 4. **Prediction Use Case**
```
execute(data, model_path)
  â”‚
  â”œâ”€â–º Load model
  â”‚    â””â”€â–º model = repository.load(model_path)
  â”‚
  â”œâ”€â–º Prepare features
  â”‚    â”œâ”€â–º Select same features as training
  â”‚    â”œâ”€â–º Handle missing values
  â”‚    â””â”€â–º Encode categoricals
  â”‚
  â”œâ”€â–º Make predictions
  â”‚    â”œâ”€â–º predictions = model.predict(X)
  â”‚    â””â”€â–º confidence = model.predict_proba(X) [if available]
  â”‚
  â””â”€â–º Return Prediction entity
```

### 5. **ML Pipeline Use Case** (End-to-End)
```
execute(source, model_config, perform_eda=True, eda_output_dir, model_output_path)
  â”‚
  â”œâ”€â–º [Step 1] Data Ingestion
  â”‚    â””â”€â–º processed_data = data_ingestion_use_case.execute(source)
  â”‚
  â”œâ”€â–º [Step 2] EDA (if perform_eda=True)
  â”‚    â””â”€â–º eda_report = eda_use_case.execute(processed_data, output_dir)
  â”‚
  â”œâ”€â–º [Step 3] Model Training
  â”‚    â””â”€â–º trained_model = training_use_case.execute(processed_data, config)
  â”‚
  â”œâ”€â–º [Step 4] Prediction
  â”‚    â””â”€â–º predictions = prediction_use_case.execute(data, model_path)
  â”‚
  â””â”€â–º Return complete results dictionary
       {
         'processed_data': ProcessedData,
         'eda_report': EDAReport,
         'trained_model': TrainedModel,
         'predictions': Prediction
       }
```

---

## ğŸ”§ Component Interaction Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLI Application                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Container (DI)                             â”‚
â”‚  Creates and injects all dependencies                        â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚          â”‚          â”‚          â”‚          â”‚
  â–¼          â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚ UC1 â”‚  â”‚ UC2 â”‚  â”‚ UC3 â”‚  â”‚ UC4 â”‚  â”‚ UC5 â”‚
â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜
   â”‚        â”‚        â”‚        â”‚        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Infrastructure Components                          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Readers â”‚  â”‚Processor â”‚  â”‚Analyzerâ”‚  â”‚  Trainer â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚Predictorâ”‚  â”‚Repositoryâ”‚  â”‚ Logger â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Supported ML Models

| Model | Type | Use Case | Key Parameters |
|-------|------|----------|----------------|
| **Linear Regression** | Regression | Continuous prediction | - |
| **Logistic Regression** | Classification | Binary/Multi-class | max_iter, solver, C |
| **Decision Tree** | Both | Interpretable model | max_depth, min_samples_split |
| **Random Forest** | Both | Ensemble, robust | n_estimators, max_depth |
| **Gradient Boosting** | Both | High performance | learning_rate, n_estimators |

---

## ğŸ“¦ File Organization

```
ML_Ollama/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/              # Business logic core
â”‚   â”‚   â”œâ”€â”€ entities.py      # Business entities
â”‚   â”‚   â”œâ”€â”€ repositories.py  # Interface contracts
â”‚   â”‚   â””â”€â”€ value_objects.py # Immutable objects
â”‚   â”‚
â”‚   â”œâ”€â”€ application/         # Use cases
â”‚   â”‚   â””â”€â”€ use_cases/
â”‚   â”‚       â”œâ”€â”€ data_ingestion.py
â”‚   â”‚       â”œâ”€â”€ eda.py
â”‚   â”‚       â”œâ”€â”€ model_training.py
â”‚   â”‚       â”œâ”€â”€ prediction.py
â”‚   â”‚       â””â”€â”€ ml_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/      # Technical implementations
â”‚   â”‚   â”œâ”€â”€ data_readers/    # CSV, TXT, PDF readers
â”‚   â”‚   â”œâ”€â”€ processing/      # Data processor, EDA
â”‚   â”‚   â”œâ”€â”€ ml/              # Models, predictor
â”‚   â”‚   â”œâ”€â”€ persistence/     # Data repository
â”‚   â”‚   â””â”€â”€ config/          # Settings, DI container
â”‚   â”‚
â”‚   â””â”€â”€ presentation/        # User interfaces
â”‚       â””â”€â”€ cli.py           # Command-line interface
â”‚
â”œâ”€â”€ models/                  # Saved trained models (.pkl)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original data files
â”‚   â””â”€â”€ processed/          # Cleaned data files
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ eda/                # EDA visualizations
â”‚   â””â”€â”€ predictions/        # Prediction results
â”‚
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ examples/               # Example usage scripts
â””â”€â”€ full_pipeline_*.py      # Complete pipeline scripts
```

---

## ğŸš€ Execution Modes

### **Mode 1: CLI Command**
```bash
ml-pipeline run-pipeline data.csv --target-column price --model-type random_forest
```

### **Mode 2: Python Script**
```python
from src.infrastructure.config.container import Container
pipeline = container.ml_pipeline_use_case
results = pipeline.execute(source, config)
```

### **Mode 3: Full Pipeline Script**
```bash
python full_pipeline_random_forest.py
```

---

## ğŸ” Key Design Patterns Used

1. **Dependency Injection**: Container manages all dependencies
2. **Factory Pattern**: Data reader selection based on file type
3. **Repository Pattern**: Data and model persistence abstraction
4. **Strategy Pattern**: Different ML models, different readers
5. **Use Case Pattern**: Business logic orchestration
6. **Entity Pattern**: Rich domain models

---

## ğŸ“ˆ Quality Assurance

- **Data Quality Metrics**: Completeness, consistency, validity scores
- **Model Metrics**: Accuracy, precision, recall, F1, MSE, RÂ²
- **Feature Importance**: Understand model decisions
- **Logging**: Comprehensive logging at all levels
- **Validation**: Data quality checks at each step

---

This architecture ensures:
âœ… **Separation of Concerns**: Each layer has single responsibility
âœ… **Testability**: Easy to unit test each component
âœ… **Maintainability**: Changes in one layer don't affect others
âœ… **Scalability**: Easy to add new models, readers, or features
âœ… **Extensibility**: Plugin new components without breaking existing code
